---
title: "Data-Mining-HW3"
author: "Parker Gauthier"
date: "4/4/2022"
output: md_document
---


```{r include=FALSE}
if (!("librarian" %in% rownames(utils::installed.packages()))) {
  utils::install.packages("librarian")
}

librarian::shelf( 
  cran_repo = "https://cran.microsoft.com/",
  ask = FALSE,
  stats, 
  here,
  kableExtra,
  ggthemes,
  tidyverse,
  lubridate,
  haven,
  lmtest,
  gganimate,
  gapminder,
  stargazer,
  snakecase,
  mosaic,
  dplyr,
  esquisse,
  plotly,
  modelr,
  rsample,
  caret,
  foreach,
  parallel,
  gamlr,
  glmnet,
  rpart,
  rpart.plot,
  rsample,
  randomForest,
  gbm,
  pdp,
  ggmap,
  devtools,
)

here::i_am("code/build.Rmd")
```

## What Causes What?

### 1.) Why can’t I just get data from a few different cities and run the regression of “Crime” on “Police” to understand how more cops in the streets affect crime? (“Crime” refers to some measure of crime rate and “Police” measures the number of cops in a city.)

```
```
  In a vast majority of situations, establishing causation is not as simple as running a regression on two variables and calling it a day.  Although there may be a significant relationship between a variable of interest and a particular covariate, it is common that there is much more explaining the change in a target variable's value.  In the case of regressing "Police" against "Crime", a particular city's crime rate could be affected by many other factors such as population density or public education spending.  When adding covariates such as these to a regression, we could see that variations in crime are less explained by policing and more so by other factors.  With this in mind, researchers have developed methods to extract causality from their models, helping us see the true effect of "Police" on "Crime."
  
  
### 2.) How were the researchers from UPenn able to isolate this effect? Briefly describe their approach and discuss their result in the “Table 2” below, from the researchers' paper.
```
```
  Researchers from UPenn used an interesting method to extrapolate the true effect of police presence on crime rate in Washington D.C.  Fairly unique to the nation's capital is the utilization of terror alert levels, which are designed to establish a greater police presence in the city to thwart varying threats of terrorism. The researchers took advantage of this unique situation to find the causal effect of "Police" on "Crime." In one regression, they observed that, on "High-Alert" days, higher police presence was associated with lower crime rates. In another, the researchers controlled for METRO ridership, and still noted a significant negative relationship between "High-Alert" and "Crime." This was paired with a positive relationship between "Crime" and METRO useage, as was expected. These regressions showed a clear 'before and after' effect on the variable of interest.

### 3.) Why did they have to control for Metro ridership? What was that trying to capture?
```
```
  While gathering this data, the researchers navigated around a potential flaw in their research design.  They called into question the effect of alert levels on general activity within the city.  If threat-levels are high, were less people going to go about their day as they normally would? If so, this could explain lower crime rates, deterring the researchers from establishing a causal effect between "Police" and "Crime."  The researchers decided to measure the usage of the city's METRO during varying alert levels.  They saw that, even when including ridership in their model, greater police presence (by proxy of 'High-Alert') still affected crime rates negatively.  Moreover, ridership was generally unaffected by the alert levels.  Ultimately, the researchers argued there was a theoretically sound reason to measure METRO ridership and controlled for it in their model.


### 4.) Below I am showing you "Table 4" from the researchers' paper. Just focus on the first column of the table. Can you describe the model being estimated here? What is the conclusion?
```
```
  This table shows how crime rates were affected during 'High Alert' status in different areas of the city.  This was achieved by interacting the 'High Alert' variable with the differing areas.  We can see that crime rates were reduced by a sizable magnitude in 'District 1' while all other districts did not see a statistically significant decline in crime rates.  Furthermore, there was still a statistically significant increase in crime when increasing midday ridership.  These relationships may show that police presence increases mostly in District 1 when the city is under high alert.  Conversely, if police presence is being increased uniformly across districts, there could be something else explaining the decrease in crime in District 1 while under high alert.

## Tree Modeling: Dengue Cases


In this analysis, we will look at which model preforms best when predicting dengue cases.  The models of interest are CART, random forest, and gradient-boosted trees.  In this order, we will calculate each of their out-of-sample performance then take the best model to make some partial dependence plots. Let's get going!

```{r include = FALSE}
#Reading and separating the data

dengue = read.csv(here("data/dengue.csv"))

dengue$city = factor(dengue$city)
dengue$season = factor(dengue$season)

dengue_split = initial_split(dengue, prop = .8)

dengue_train = training(dengue_split)

dengue_test = testing(dengue_split)

```
### Building our models:

#### CART

We will build this model using R's rpart() function, regressing total_cases against all other variables.  Initially, we will build a very complex tree, using a high complexity parameter for our splits.  We will then prune our tree to find the optimal complexity parameter. 
```
```
Below shows a plot of our cross validated error for increasing levels of our complexity parameter.  We can see that it bottoms out very quickly, so a model with the parameter that minimizes this error will still be quite simple.  This is opposed to choosing the simplest model within one standard error of the minimum, which we would do if our error was minimized with a very complex model. In this case, doing this would likely lead to a model that was too simple, leading our model to not split at all.  Here, it seems we can afford to choose the parameter that minimizes cross-validated error.

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
# building the model:

dengue_CART = rpart(total_cases ~ ., data = dengue_train, control = rpart.control(cp = .000001))

plotcp(dengue_CART)
```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror)
  cp_opt = out$CP[out$xerror == thresh]
  prune(my_tree, cp=cp_opt)
}

dengue_CART = prune_1se(dengue_CART)
```
```
```
Our tree model, depending on training and testing splits, will typically, at the very least, split on the variable min_air_temp_k:
```
```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
# Plotting tree for fun
rpart.plot(dengue_CART, type = 4, digits = 4, tweak = 1.1, fallen.leaves = TRUE, extra = 1)

```
```
```

Now that we have our model using CART, let us move on to the next!

#### Random Forests

Next on our list is our Random Forests model.  Like the CART model, we will run total_cases against all covariates in the model.  We will impute NA values in our data set for ease of use.
```
```
Important to note, due to the nature of random forests, particularly in the repeated random sampling of the data set, cross-validation is not required as it was for the CART model.
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
#building the model
dengue_RANDO = randomForest(total_cases~ ., data = dengue_train, importance = TRUE, na.action = na.roughfix)

```
Below shows our variable importance from running this model:
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
#variable importance plot
varImpPlot(dengue_RANDO, type = 1)

```
```
```
Unsurprisingly, min_air_temp_k and season are among the most import variables in this model, consistent with our CART model.

#### Gradient Boosted Trees

Finally we will build a model using Gradient Boosted Trees.  To build the best model we can, we will first plot the cross validated error to find the optimal iteration of trees to use. 

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
#building the model

boost = gbm(total_cases~., data = dengue_train, interaction.depth = 4, n.trees=500, shrinkage = .05, cv.folds = 10, distribution = "gaussian")

gbm.perf(boost)

```
```
```
Above, the green line represents our cross validated error and the number displayed is the number of iterations minimizing this.  We will optimize our model according to this iteration of trees used.

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
optimal_iter = function(boostie) {
  df = data.frame(iteration = c(1:boostie$n.trees), cv_error = boostie$cv.error)
  min = min(df$cv_error)
  optimal = df$iteration[df$cv_error == min]
  boostie = gbm(total_cases~., data = dengue_train, interaction.depth = 4, n.trees= optimal, shrinkage = .05, cv.folds = 10, distribution = "gaussian")
}

boost = optimal_iter(boost)
```

### Out-of-sample RMSEs

Alright, the moment we've been waiting for.  We have built our models, now let's see our out-of-sample performance for each using the testing data we set aside earlier.

*CART:*
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
# RMSE for CART

rmse(dengue_CART, dengue_test)

```
*Random Forests:*
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

rmse(dengue_RANDO, dengue_test)

```
*Gradient Boosted Trees:*
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

rmse(boost, dengue_test)

```

We can clearly see that our Random Forests model outperforms the other two. Now that we have our best-performing model, we can create some partial dependency plots for key variables of interest:

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

pdp::partial(dengue_RANDO, pred.var = 'specific_humidity') %>%
  ggplot()+
  geom_line(aes(x = specific_humidity, y = yhat)) +
  labs(title = "Partial Dependence on 'specific_humidity'") +
  theme_classic()

```
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

pdp::partial(dengue_RANDO, pred.var = 'precipitation_amt') %>%
  ggplot()+
  geom_line(aes(x = precipitation_amt, y = yhat)) +
  labs(title = "Partial Dependence on 'precipitation_amt'") +
  theme_classic()


```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

pdp::partial(dengue_RANDO, pred.var = 'min_air_temp_k') %>%
  ggplot()+
  geom_line(aes(x = min_air_temp_k, y = yhat)) +
  labs(title = "Partial Dependence on 'min_air_temp_k'") +
  theme_classic()

```

```
```
We can see from our plots that as these variables increase, so does their impact on the predicted number of cases.  This is likely because increases in these factors are known to be associated with more hospitable conditions for mosquitoes. With increases in these variables, we are likely to see more mosquito proliferation, leading to more incidences of dengue fever.

## Predictive Model Building: Green Certification

For this analysis, we will attempt to build the best model possible for predicting revenue per square foot per calender year for commercial rental properties in the United States.  This will be done by taking the rent charged per square foot per year and multiplying it by the building's occupancy rate.  A key variable of interest will be 'green certification,' showing us if a building is classified as 'green' affects its revenue.

```
```

In this process, we will be splitting our data into a training set and testing set, building a few models using the training data, and selecting the one that has the best out-of-sample performance using our testing set. All cross validation will be done on our training data before testing out-of-sample performance.
```{r include = FALSE}
green = read.csv(here("data/greenbuildings.csv"))
```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

### Data preparation

# mutating data: getting revenue variable for (Rent * leasing rate) and certification variable if building was LEED or Energy Star certified:

green = green %>%
  mutate(revenue = Rent * (leasing_rate/100)) %>% select(-Rent, -leasing_rate, -LEED, -Energystar) %>% na.roughfix()

```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
# splitting data
green_split = initial_split(green, prob = .8)
green_train = training(green_split)
green_test = testing(green_split)
```

### Linear model using Lasso regression

Our first model will be constructed using the Lasso regression method.  This will give us a linear model with the most important features selected automatically.   The root mean squared error is reported below as this models out-of-sample performance:
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
# Building the model

lasso_x = model.matrix(revenue~.-1, data = green_train)

lasso_y = green_train$revenue

lasso = cv.glmnet(lasso_x, lasso_y, alpha =1)

best_lambda = lasso$lambda.min
```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
# calculating out of sampler performance
lasso_x_test = model.matrix(revenue~.-1, data = green_test)

lasso_pred = predict(lasso, s = best_lambda, newx = lasso_x_test)

RMSE(lasso_pred, green_test$revenue)
```

### Random Forests

Our next model will be built using random forests. As we can see, its out-of-sample performance far exceeds our linear model:
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
# Buidling the model
green_RF = randomForest(revenue~ ., data = green_train, importance = TRUE, na.action = na.roughfix)

```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
#out of sample performance
rmse(green_RF, green_test)

```

### Gradient Boosted Trees

Finally, we will see how an optimized gradient boosted tree model stacks up:  
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
green_boost = gbm(revenue~., data = green_train, interaction.depth = 4, n.trees=500, shrinkage = .05, cv.folds = 6, distribution = "gaussian")

optimal_iter = function(boostie) {
  df = data.frame(iteration = c(1:boostie$n.trees), cv_error = boostie$cv.error)
  min = min(df$cv_error)
  optimal = df$iteration[df$cv_error == min]
  boostie = gbm(revenue~., data = green_train, interaction.depth = 4, n.trees= optimal, shrinkage = .05, cv.folds = 6, distribution = "gaussian")
}

green_boost = optimal_iter(green_boost)

```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
rmse(green_boost, green_test)
```
```
```
We can see from the results above that our random forests model performed the best.  We will use this model for the rest of our analysis by finding variables of import and making some partial dependence plots.


### Variaable Importance Plot:
``````{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
varImpPlot(green_RF, type = 1)
```

The plot above reveals some interesting information on what is affecting revenues for these properties. Perhaps unsurprisingly, size, age, and Cit_Market_Rent (average rent per square foot per calender year in the building's local market) seem to be some of the most significant variables in our data set.  Green_rating falls quite short here, as it seems to have little effect on revenues.

### Particial Dependence Plots

To help us visualize how our variable of import affect revenues, we will display some of their partial dependence plots

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
pdp::partial(green_RF, pred.var = 'size') %>%
  ggplot()+
  geom_line(aes(x = size, y = yhat)) +
  labs(title = "Partial Dependence on 'size'") +
  theme_classic()
```
```
```
We can see above that for larger properties predicted revenues are higher with predicting plateauing at a particular point.
```
```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
pdp::partial(green_RF, pred.var = 'age') %>%
  ggplot()+
  geom_line(aes(x = age, y = yhat)) +
  labs(title = "Partial Dependence on 'age'") +
  theme_classic()
```
```
```
On the other hand, age seems to have an initial increasing relationship with revenues then a steady decline to about 100 years old followed by an upward spike.  This may be the result of older buildings being over 100 years old being in densly populated areas causing prices and revenues to go up.

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
pdp::partial(green_RF, pred.var = 'City_Market_Rent') %>%
  ggplot()+
  geom_line(aes(x = City_Market_Rent, y = yhat)) +
  labs(title = "Partial Dependence on 'City_Market_Rent'") +
  theme_classic()
```

Finally, as with size, City_Market_Rent has an increasing relationship with predicted revenues.  This hints that certain areas have higher demand for commercial real estate, driving revenues upward.

### Conculsions
Ultimately, for predicting revenue per square foot per calender year, building a model using random forests gave us the best performance.  We saw that size, age, and City_Market_Rent greatly affected these revenues.  Additionally, green certification had little affect on our variable of interest.

## Predictive Model Building: California housing

Similar to our last analysis, we will again attempt to build the best model possible in predicting median housing values in California.  This will be done by seperating our data into training and testing sets, building and cross validating models using our training data, and testing out-of-sample performance using root mean squared error as a measure.
```{r include = FALSE}
CAhousing = read.csv(here("data/CAhousing.csv"))
```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
# cleaning data to standardize for # of bedrooms:

CAhousing =  CAhousing %>%
  mutate(avRooms = round(totalRooms/households, digits = 3), avBedrooms = round(totalBedrooms/households, digits = 3)) %>%
  select(-totalBedrooms, -totalRooms) %>%
  na.roughfix()

```


```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
# splitting data for training and testing

CAhousing_split = initial_split(CAhousing, prob = .8)
CA_train = training(CAhousing_split)
CA_test = testing(CAhousing_split)


```
```
```
Below are the RMSEs for three different models: Lasso regression, Random Forests, and Gradient Boosted Trees.

### Lasso
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

lasso_x = model.matrix(medianHouseValue~.-1, data = CA_train)

lasso_y = CA_train$medianHouseValue

lasso = cv.glmnet(lasso_x, lasso_y, alpha =1)

best_lambda = lasso$lambda.min

lasso_x_test = model.matrix(medianHouseValue~.-1, data = CA_test)

lasso_pred = predict(lasso, s = best_lambda, newx = lasso_x_test)

RMSE(lasso_pred, CA_test$medianHouseValue)
```
### Random Forests
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

CA_RF = randomForest(medianHouseValue~ ., data = CA_train, importance = TRUE, na.action = na.roughfix)

rmse(CA_RF, CA_test)
```
### Gradient Boosted Trees
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
CA_boost = gbm(medianHouseValue~., data = CA_train, interaction.depth = 5, n.trees=500, shrinkage = .1, cv.folds = 6, distribution = "gaussian")

optimal_iter = function(boostie) {
  df = data.frame(iteration = c(1:boostie$n.trees), cv_error = boostie$cv.error)
  min = min(df$cv_error)
  optimal = df$iteration[df$cv_error == min]
  boostie = gbm(medianHouseValue~., data = CA_train, interaction.depth = 5, n.trees= optimal, shrinkage = .1, cv.folds = 6, distribution = "gaussian")
}

CA_boost = optimal_iter(CA_boost)

rmse(CA_boost, CA_test)
```
```
```
Here, our gradient boosted trees model performs the best.


#### Plotting Median House Value

Using the original data and predictions from our random forest model we will do three projections of values onto a map of California. There will be a plot for actual, predicted, and residual values for median housing prices on this map.

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
#retrieving data to plot over california
states = map_data("state")
cali = subset(states, region == 'california')
```

```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

cali_map_act =  ggplot(cali, aes(x = long, y = lat, group = group)) + 
  coord_fixed(1.3) +
  geom_polygon(color = "black", fill = "tan") +
  theme_map() +
  geom_point(data = CAhousing, mapping =  aes(x=longitude,y=latitude, color = medianHouseValue, group = NA, alpha = .95)) +
  guides(alpha = FALSE) +
  scale_color_continuous(type = "viridis") +
  labs(title = "Median House Values - Actual", color = "Median House Valuse")

cali_map_act
```



```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

CAhousing = CAhousing %>%
  mutate(medianHouseValue_pred = predict(CA_boost, CAhousing, type="response")) 

cali_map_pred =  ggplot(cali, aes(x = long, y = lat, group = group)) + 
  coord_fixed(1.3) +
  geom_polygon(color = "black", fill = "tan") +
  theme_map() +
  geom_point(data = CAhousing, mapping =  aes(x=longitude,y=latitude, color = medianHouseValue_pred, group = NA, alpha = .95)) +
  guides(alpha = FALSE) +
  scale_color_continuous(type = "viridis") +
  labs(title = "Median House Values - Predicted", color = "Median House Valuse")

cali_map_pred

```


```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

CAhousing = CAhousing %>%
  mutate(medianHouseValue_res = (medianHouseValue - medianHouseValue_pred)^2)

cali_map_res =  ggplot(cali, aes(x = long, y = lat, group = group)) + 
  coord_fixed(1.3) +
  geom_polygon(color = "black", fill = "tan") +
  theme_map() +
  geom_point(data = CAhousing, mapping =  aes(x=longitude,y=latitude, color = medianHouseValue_res, group = NA, alpha = .1)) +
  guides(alpha = FALSE) +
  scale_color_continuous(type = "viridis") +
  labs(title = "Median House Values - Squared Residuals", color = "Median House Valuse")

cali_map_res
```
```
```
From these plots we can see that housing values tend to be greater on the coast and in more densely populated areas.  Our predictions follow the trends in the actual data and we can see that our greatest residuals are in these areas as well.  This is likely due to greater fluctuations in price in densely populated areas.  Ultimately, our gradient boosted trees model seems to perform well when predicting median housing values in California.

